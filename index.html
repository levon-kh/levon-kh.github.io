
    <!doctype html>
<html lang="en">

<head>
  <!-- Required meta tags -->
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <!-- Bootstrap CSS -->
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/css/bootstrap.min.css"
    integrity="sha384-Gn5384xqQ1aoWXA+058RXPxPg6fy4IWvTNh0E263XmFcJlSAwiGgFAW/dAiS6JXm" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/all.min.css" integrity="sha512-xh6O/CkQoPOWDdYTDqeRdPCVd1SpvCA9XXcUnZS2FmJNp1coAFzvtCN9BmamE+4aHK8yyUHUSCcJHgXloTyT2A==" crossorigin="anonymous" referrerpolicy="no-referrer" />

  <title>Levon Khachatryan</title>
  <link rel="icon" type="image/x-icon" href="assets/idea.png">
</head>

<body>
    <div class="container">
        <div class="row">
            <div class="col-md-1"></div>
            <div class="col-md-10">
                <div class="row" style="margin-top: 3em;">
                    <div class="col-sm-12" style="margin-bottom: 1em;">
                    <h3 class="display-4" style="text-align: center;">Levon Khachatryan</h3>
                    </div>
                    <br>
                    <div class="col-md-10" style="">
                        
                <p>
                    I am a senior machine learning researcher specializing in computer vision, with expertise in generative modeling, segmentation and classical computer vision. Currently driving innovation at <a href="https://picsart.com/" target="_blank">Picsart</a>, where I contribute to groundbreaking projects in image and video domains. Additionally, I share my knowledge and expertise as a Computer Vision Lecturer in the Applied Statistics and Data Science Master’s program at <a href="https://www.ysu.am/en" target="_blank">Yerevan State University</a>, while also supervising master’s theses for students.
                </p>
                <p>
                  My current research focuses on Generative AI in Computer Vision, particularly I am recently working on:
                  <ul>
                    <li>  Image/Video Generation
                    <li>  Controllable Image/Video Editing
                  </ul>
                </p>
                <p>
                    <a href="https://scholar.google.com/citations?user=CYcBf3IAAAAJ&hl=en" target="_blank" style="margin-right: 5px"><i class="fa-solid fa-book"></i>Google Scholar</a>
                    <a href="https://www.semanticscholar.org/author/Levon-Khachatryan/2212523911" target="_blank" style="margin-right: 5px"><i class="fa-solid fa-book"></i>Semantic Scholar</a>
                    <a href="assets/pdf/resume.pdf" target="_blank" style="margin-right: 5px"><i class="fa fa-address-card fa-lg"></i> CV</a>
                    <a href="mailto:lev1khachatryan@yahoo.com" style="margin-right: 5px"><i class="far fa-envelope-open fa-lg"></i> Mail</a>
                    <a href="https://www.linkedin.com/in/levonkhachatryan/" target="_blank" style="margin-right: 5px"><i class="fab fa-linkedin fa-lg"></i> LinkedIn</a>
                </p>
    
                    </div>
                    <div class="col-md-2" style="">
                        <img src="assets/img/profile.jpg" class="img-thumbnail" width="512px" alt="Profile picture">
                    </div>
                </div>
                <div class="row" style="margin-top: 1em;">
                    <div class="col-sm-12" style="">

<h4>Publications</h4>
<div style="margin-bottom: 3em;"> <div class="row"><div class="col-sm-3"><img src="assets/img/publications/streaming_t2v.png" class="img-fluid img-thumbnail" alt="Project image"></div><div class="col-sm-9">
    <a href="https://arxiv.org/abs/2403.14773" target="_blank">StreamingT2V: Consistent, Dynamic, and Extendable Long Video Generation from Text</a>
    <br>Roberto Henschel*</a>, <span style="font-weight: bold";>Levon Khachatryan*</span>, Daniil Hayrapetyan*</a>, Hayk Poghosyan</a>, Vahram Tadevosyan</a>, Zhangyang Wang</a>, Shant Navasardyan</a>, Humphrey Shi</a>,<br>
    <span style="font-style: italic;">arXiv.org (under review) </span>, 2024 <br>
    <a href="https://streamingt2v.github.io/" target="_blank">Project Page</a> / <a href="https://github.com/Picsart-AI-Research/StreamingT2V" target="_blank">Code</a> / <a href="https://huggingface.co/spaces/PAIR/StreamingT2V" target="_blank">Hugging Face</a> / <a href="https://www.youtube.com/watch?v=GDPP0zmFmQg" target="_blank">Video</a> /<button class="btn btn-link" type="button" data-toggle="collapse" data-target="#collapsechen2023gentron" aria-expanded="false" aria-controls="collapseExample" style="margin-left: -6px; margin-top: -2px;">Bibtex</button><div class="collapse" id="collapsechen2023gentron"><div class="card card-body"><pre><code>@article{streamingt2v,
    title={StreamingT2V: Consistent, Dynamic, and Extendable Long Video Generation from Text},
    author={Henschel, Roberto and Khachatryan, Levon and Hayrapetyan, Daniil and Poghosyan, Hayk and Tadevosyan, Vahram and Wang, Zhangyang and Navasardyan, Shant and Shi, Humphrey},
    journal={arXiv preprint arXiv:2403.14773},
    year={2024}
  }
</pre></code></div></div> </div> </div> </div>

<div style="margin-bottom: 3em;"> <div class="row"><div class="col-sm-3"><img src="assets/img/publications/inter_seg.png" class="img-fluid img-thumbnail" alt="Project image"></div><div class="col-sm-9">
    <a href="https://openaccess.thecvf.com/content/WACV2024/papers/Atanyan_Continuous_Adaptation_for_Interactive_Segmentation_Using_Teacher-Student_Architecture_WACV_2024_paper.pdf" target="_blank">Continuous Adaptation for Interactive Segmentation Using Teacher-Student Architecture</a>
    <br>Barsegh Atanyan</a>, <span style="font-weight: bold";>Levon Khachatryan</span>, Shant Navasardyan</a>, Yunchao Wei</a>, Humphrey Shi</a>,<br>
    <span style="font-style: italic;">Proc. of the IEEE/CVF Winter Conference on Applications of Computer Vision (WACV) </span>, 2024 <br>
    <a href="https://openaccess.thecvf.com/content/WACV2024/supplemental/Atanyan_Continuous_Adaptation_for_WACV_2024_supplemental.pdf" target="_blank">Supplemental</a> /<button class="btn btn-link" type="button" data-toggle="collapse" data-target="#collapsechen2023gentron" aria-expanded="false" aria-controls="collapseExample" style="margin-left: -6px; margin-top: -2px;">Bibtex</button><div class="collapse" id="collapsechen2023gentron"><div class="card card-body"><pre><code>@InProceedings{Atanyan_2024_WACV,
    author    = {Atanyan, Barsegh and Khachatryan, Levon and Navasardyan, Shant and Wei, Yunchao and Shi, Humphrey},
    title     = {Continuous Adaptation for Interactive Segmentation Using Teacher-Student Architecture},
    booktitle = {Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)},
    month     = {January},
    year      = {2024},
    pages     = {789-799}
}
</pre></code></div></div> </div> </div> </div>

<div style="margin-bottom: 3em;"> <div class="row"><div class="col-sm-3"><img src="assets/img/publications/t2v0.png" class="img-fluid img-thumbnail" alt="Project image"></div><div class="col-sm-9">
    <a href="https://arxiv.org/pdf/2303.13439.pdf" target="_blank">Text2Video-Zero: Text-to-Image Diffusion Models are Zero-Shot Video Generators</a>
    <br><span style="font-weight: bold";>Levon Khachatryan*</span>, Andranik Movsisyan*</a>, Vahram Tadevosyan*</a>, Roberto Henschel*</a>, Zhangyang Wang</a>, Shant Navasardyan</a>, Humphrey Shi</a>,<br>
    <span style="font-style: italic;">Proc. of the IEEE/CVF International Conference on Computer Vision (ICCV <span style="font-weight: bold";>Oral</span>)</span>, 2023 <br>
    <a href="https://text2video-zero.github.io/" target="_blank">Project Page</a> / <a href="https://github.com/Picsart-AI-Research/Text2Video-Zero" target="_blank">Code</a> / <a href="https://huggingface.co/spaces/PAIR/Text2Video-Zero" target="_blank">Hugging Face</a> / <a href="https://www.dropbox.com/s/uv90mi2z598olsq/Text2Video-Zero.MP4?dl=0" target="_blank">Video</a> /<button class="btn btn-link" type="button" data-toggle="collapse" data-target="#collapsecong2023flatten" aria-expanded="false" aria-controls="collapseExample" style="margin-left: -6px; margin-top: -2px;">Bibtex</button><div class="collapse" id="collapsecong2023flatten"><div class="card card-body"><pre><code>@article{text2video-zero,
    title={Text2Video-Zero: Text-to-Image Diffusion Models are Zero-Shot Video Generators},
    author={Khachatryan, Levon and Movsisyan, Andranik and Tadevosyan, Vahram and Henschel, Roberto and Wang, Zhangyang and Navasardyan, Shant and Shi, Humphrey},
    journal={arXiv preprint arXiv:2303.13439},
    year={2023}
}
</pre></code></div></div> </div> </div> </div>

<div style="margin-bottom: 3em;"> <div class="row"><div class="col-sm-3"><img src="assets/img/publications/face_clip.png" class="img-fluid img-thumbnail" alt="Project image"></div><div class="col-sm-9">
    <a href="https://ieeexplore.ieee.org/document/10310257" target="_blank">FaceCLIP: Facial Image-to-Video Translation via A Brief Text Description</a> <br> Jiayi Guo</a>, Hayk Manukyan</a>, Chenyu Yang</a>, Chaofei Wang</a>, <span style="font-weight: bold";>Levon Khachatryan</span>, Shant Navasardyan</a>, Shiji Song</a>, Humphrey Shi</a>, Gao Huang</a>,<br>
    <span style="font-style: italic;">IEEE Transactions on Circuits and Systems for Video Technology (TCSVT),</span> 2023 <br>
    <button class="btn btn-link" type="button" data-toggle="collapse" data-target="#collapsecong2023learning" aria-expanded="false" aria-controls="collapseExample" style="margin-left: -6px; margin-top: -2px;">Bibtex</button><div class="collapse" id="collapsecong2023learning"><div class="card card-body"><pre><code>@ARTICLE{10310257,
  author={Guo, Jiayi and Manukyan, Hayk and Yang, Chenyu and Wang, Chaofei and Khachatryan, Levon and Navasardyan, Shant and Song, Shiji and Shi, Humphrey and Huang, Gao},
  journal={IEEE Transactions on Circuits and Systems for Video Technology}, 
  title={FaceCLIP: Facial Image-to-Video Translation via A Brief Text Description}, 
  year={2023},
  volume={},
  number={},
  pages={1-1},
  keywords={Task analysis;Training;Faces;Solid modeling;Three-dimensional displays;Image synthesis;Image reconstruction;autoencoder;CLIP;facial video generation;image-to-video translation;text-guided;transformer},
  doi={10.1109/TCSVT.2023.3330920}
}
</pre></code></div></div> </div> </div> </div>

<div style="margin-bottom: 3em;"> <div class="row"><div class="col-sm-3"><img src="assets/img/publications/sod.png" class="img-fluid img-thumbnail" alt="Project image"></div><div class="col-sm-9">
    <a href="https://ieeexplore.ieee.org/abstract/document/10183835" target="_blank">Collaborative content-dependent modeling: A return to the roots of salient object detection</a> <br> Siyu Jiao</a>, Vidit Goel</a>, Shant Navasardyan</a>, Zongxin Yang</a>,
    <span style="font-weight: bold";>Levon Khachatryan</span>, Yi Yang</a>, Yunchao Wei</a>, Yao Zhao</a>, Humphrey Shi</a>, </a><br>
    <span style="font-style: italic;">IEEE Transactions on Image Processing (TIP)</span>, 2023 <br>
    <button class="btn btn-link" type="button" data-toggle="collapse" data-target="#collapseCong_2023_CVPR" aria-expanded="false" aria-controls="collapseExample" style="margin-left: -6px; margin-top: -2px;">Bibtex</button><div class="collapse" id="collapseCong_2023_CVPR"><div class="card card-body"><pre><code>@ARTICLE{10183835,
  author={Jiao, Siyu and Goel, Vidit and Navasardyan, Shant and Yang, Zongxin and Khachatryan, Levon and Yang, Yi and Wei, Yunchao and Zhao, Yao and Shi, Humphrey},
  journal={IEEE Transactions on Image Processing}, 
  title={Collaborative Content-Dependent Modeling: A Return to the Roots of Salient Object Detection}, 
  year={2023},
  volume={32},
  number={},
  pages={4237-4246},
  keywords={Convolution;Task analysis;Head;Feature extraction;Decoding;Transformers;Object detection;Salient object detection;content-dependent modeling},
  doi={10.1109/TIP.2023.3293759}
}
</pre></code></div></div> </div> </div> </div>

<h4>Selected Recent Student Theses</h4>
<div style="margin-bottom: 3em;"> <div class="row"><div class="col-sm-3"><img src="assets/img/thesis/StyleT2V0.jpg" class="img-fluid img-thumbnail" alt="Project image"></div><div class="col-sm-9">
    <a href="https://style-t2v0.github.io/" target="_blank">StyleT2V0: Zero-Shot Short Video Generation Guided by Text and Style</a>
    <br>Astghik Chobanyan</a>, <span style="font-weight: bold";>Levon Khachatryan</span></a><br>
</pre></code></div></div> </div>

<div style="margin-bottom: 3em;"> <div class="row"><div class="col-sm-3"><img src="assets/img/thesis/DynamicImportance.jpg" class="img-fluid img-thumbnail" alt="Project image"></div><div class="col-sm-9">
    <a href="https://dynamicimportance.github.io/" target="_blank">DynamicImportance: Interactive Assignment of Word Significance in a Generalist Vision Model</a>
    <br>Meri Topuzyan</a>, <span style="font-weight: bold";>Levon Khachatryan</span></a><br>
</pre></code></div></div> </div>

<div style="margin-bottom: 3em;"> <div class="row"><div class="col-sm-3"><img src="assets/img/thesis/EdgeSR.jpg" class="img-fluid img-thumbnail" alt="Project image"></div><div class="col-sm-9">
    <a href="https://edgesr.github.io/" target="_blank">EdgeSR: Image Super-Resolution Using Edge-Guided Diffusion Models</a>
    <br>Armine Panosyan</a>, <span style="font-weight: bold";>Levon Khachatryan</span></a><br>
</pre></code></div></div> </div>

<div style="margin-bottom: 3em;"> <div class="row"><div class="col-sm-3"><img src="assets/img/thesis/MultiConcept.png" class="img-fluid img-thumbnail" alt="Project image"></div><div class="col-sm-9">
    <a href="https://multi-concept-diffusion-customization.github.io/" target="_blank">Multi-Concept Customization of Diffusion Models</a>
    <br>Mariam Gasoyan</a>, <span style="font-weight: bold";>Levon Khachatryan</span></a><br>
</pre></code></div></div> </div>

<!-- Optional JavaScript -->
<!-- jQuery first, then Popper.js, then Bootstrap JS -->

<script src="https://code.jquery.com/jquery-3.2.1.slim.min.js"
  integrity="sha384-KJ3o2DKtIkvYIK3UENzmM7KCkRr/rE9/Qpg6aAZGJwFDMVNA/GpGFF93hXpG5KkN"
  crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.12.9/umd/popper.min.js"
  integrity="sha384-ApNbgh9B+Y1QKtv3Rn7W3mgPxhU9K/ScQsAP7hUibX39j7fakFPskvXusvfa0b4Q"
  crossorigin="anonymous"></script>
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/js/bootstrap.min.js"
  integrity="sha384-JZR6Spejh4U02d8jOt6vLEHfe/JQGiRRSQQxSfFWpi1MquVdAyjUar5+76PVCmYl"
  crossorigin="anonymous"></script>
</body>
</html>